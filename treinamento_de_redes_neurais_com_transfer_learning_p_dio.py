# -*- coding: utf-8 -*-
"""treinamento-de-redes-neurais-com-transfer-learning-p-dio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/MrSilva-HR/8e5c258f154cedf6e997257093c72130/treinamento-de-redes-neurais-com-transfer-learning-p-dio.ipynb
"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

!pip install rarfile
import os
import rarfile

# Se você usou o nome 'meu_dataset.rar'
rar_file_name = 'meu_dataset.rar' # Altere se o nome for diferente
extraction_path = '/content/dataset/' # Onde os dados serão descompactados no Colab

# Cria o diretório de destino se não existir
os.makedirs(extraction_path, exist_ok=True)

# Descompacta o arquivo
with rarfile.RarFile(rar_file_name, 'r') as rar_ref:
    rar_ref.extractall(extraction_path)

print(f"Dados descompactados em: {extraction_path}")
# Verifique a estrutura de pastas
!ls {extraction_path}
!ls {extraction_path}/meu_dataset/treino # Adapte ao nome da sua pasta raiz dentro do zip

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Defina os caminhos para os diretórios de treino e validação
train_dir = os.path.join(extraction_path, 'meu_dataset', 'treino')
validation_dir = os.path.join(extraction_path, 'meu_dataset', 'validacao')

# Crie geradores de dados para treino e validação
# A normalização (rescale=1./255) é uma etapa de pré-processamento comum
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),  # Redimensione todas as imagens para 150x150
        batch_size=20,
        class_mode='binary') # 'binary' porque temos duas classes (gato e cachorro)

validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

from tensorflow.keras import layers
from tensorflow.keras import models

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu',
                        input_shape=(150, 150, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dropout(0.5))  # Adicionando a camada de Dropout
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid')) # Sigmoid para classificação binária

model.summary()

from tensorflow.keras import optimizers

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(learning_rate=1e-4),
              metrics=['acc'])

history = model.fit(
      train_generator,
      steps_per_epoch=100,  # The number of batches to draw from the generator per epoch.
      epochs=30,
      validation_data=validation_generator,
      validation_steps=50) # The number of batches to draw from the validation generator for evaluation.

import os
from PIL import Image

def find_and_remove_corrupted_images(directory):
    for root, _, files in os.walk(directory):
        for f in files:
            try:
                img_path = os.path.join(root, f)
                img = Image.open(img_path)
                img.verify()
            except (IOError, SyntaxError) as e:
                print(f"Removing corrupted image: {img_path}")
                os.remove(img_path)

find_and_remove_corrupted_images(train_dir)
find_and_remove_corrupted_images(validation_dir)

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Acurácia de treino')
plt.plot(epochs, val_acc, 'b', label='Acurácia de validação')
plt.title('Acurácia de treino e validação')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Perda de treino')
plt.plot(epochs, val_loss, 'b', label='Perda de validação')
plt.title('Perda de treino e validação')
plt.legend()

plt.show()

"""# Documentação do Processo: Treinamento de um Classificador de Imagens

## Objetivo
O objetivo deste projeto foi treinar uma Rede Neural Convolucional (CNN) para classificar imagens de gatos e cachorros. O processo envolveu a preparação dos dados, a construção do modelo, o treinamento e a otimização para melhorar o desempenho.

---

### Etapa 1: Preparação e Extração dos Dados

A primeira etapa consistiu em carregar e extrair o conjunto de dados de imagens.

*   **Ação Inicial:** Foi feito o upload de um arquivo `meu_dataset.rar` contendo as imagens de treino e validação.
*   **Falha Encontrada:** O código inicial estava preparado para extrair um arquivo `.zip`, o que resultou em um erro `FileNotFoundError`, pois o programa não encontrou o arquivo zip esperado.
*   **Solução Aplicada:**
    1.  Instalamos a biblioteca `rarfile`, que é capaz de manipular arquivos de compressão `.rar`.
    2.  Modificamos o script para utilizar a biblioteca `rarfile` e alteramos o nome do arquivo de `meu_dataset.zip` para `meu_dataset.rar`, garantindo que o arquivo correto fosse encontrado e extraído com sucesso.

---

### Etapa 2: Treinamento Inicial do Modelo e Erros de Dados

Com os dados extraídos, construímos e iniciamos o treinamento de uma CNN básica.

*   **Ação Inicial:** Um modelo de CNN foi definido, compilado e o processo de treinamento foi iniciado com a função `model.fit()`.
*   **Falha Encontrada 1: Imagem Corrompida**
    *   **Problema:** O treinamento foi abruptamente interrompido por um `UnidentifiedImageError`. Este erro indicava que pelo menos um arquivo de imagem no conjunto de dados estava corrompido ou em um formato que a biblioteca de processamento de imagens (PIL) не conseguia ler.
    *   **Solução:** Implementamos um script auxiliar que percorreu todos os arquivos nos diretórios de treino e validação. O script tentou abrir cada imagem e, caso encontrasse um arquivo corrompido (como o `gato/666.jpg`), ele o removia do diretório.
*   **Falha Encontrada 2: Arquivo Não Encontrado Pós-Limpeza**
    *   **Problema:** Após a remoção da imagem corrompida, uma nova tentativa de treinamento resultou em um `FileNotFoundError`. Isso ocorreu porque os geradores de dados (`ImageDataGenerator`) foram criados *antes* da remoção do arquivo e ainda mantinham uma referência a ele.
    *   **Solução:** Para resolver isso, a célula que cria os `ImageDataGenerator` foi executada novamente. Isso forçou os geradores a re-escanear os diretórios, agora limpos, e a criar um novo índice de arquivos válidos, eliminando a referência ao arquivo deletado.

---

### Etapa 3: Análise de Desempenho e Overfitting

Após o treinamento ser concluído com sucesso, o próximo passo foi avaliar a performance do modelo.

*   **Ação Inicial:** Plotamos gráficos da acurácia e da perda (loss) de treino e validação ao longo das épocas.
*   **Falha Encontrada (Conceitual): Overfitting**
    *   **Problema:** Os gráficos mostraram um claro sinal de **overfitting**. A acurácia de treino aproximava-se de 100%, enquanto a acurácia de validação estagnava em um nível muito mais baixo. Isso significa que o modelo estava "decorando" os dados de treino, mas não conseguia generalizar seu aprendizado para novas imagens (os dados de validação).
    *   **Solução:** Para combater o overfitting, adicionamos uma camada de **Dropout** ao modelo. Dropout é uma técnica de regularização que desativa aleatoriamente uma fração dos neurônios durante o treinamento, forçando a rede a aprender padrões mais robustos e menos dependentes de neurônios específicos.

---

### Etapa 4: Retreinamento e Avaliação Final

Com o modelo aprimorado, realizamos o processo de treinamento novamente.

*   **Ação Inicial:** O novo modelo, agora com a camada de Dropout, foi recompilado e treinado novamente com os mesmos dados.
*   **Resultado:** Plotamos novamente os gráficos de acurácia e perda. Desta vez, as curvas de treino e validação estavam muito mais próximas, indicando que o overfitting foi significativamente reduzido. O modelo final apresentou um desempenho mais equilibrado e uma capacidade de generalização muito melhor.

## Conclusão
O processo demonstrou um fluxo de trabalho comum em projetos de Deep Learning: partindo de um modelo base, encontramos e solucionamos problemas relacionados aos dados (arquivos corrompidos) e ao próprio modelo (overfitting). Ao final, chegamos a um modelo mais robusto e eficaz.

# Task
Suba o projeto do notebook para o GitHub.

## Salvar o notebook

### Subtask:
Salvar o notebook

## Inicializar o git e adicionar o notebook

### Subtask:
Inicializar um repositório Git no ambiente do Colab e adicionar seu arquivo de notebook a ele.

**Reasoning**:
I will start by initializing a new Git repository in the current directory using `!git init`. This is the first step in creating a version-controlled project. Then, to add the notebook file to the staging area, I need to know its name. I will use `!ls` to list the files in the current directory, find the notebook's filename, and then use `!git add` to stage it.
"""

!git init
!ls

"""**Reasoning**:
The previous command's output from `!ls` did not show the notebook file. This is because Colab notebooks are not always directly visible in the `/content/` directory with a simple `!ls` command. I need to find the correct filename. I'll try a more specific `!ls` command targeting `.ipynb` files to find the notebook's name, then add it to the git repository.


"""

!ls *.ipynb

"""## Inicializar o git e adicionar o notebook

### Subtask:
Inicializar um repositório Git no ambiente do Colab e adicionar seu arquivo de notebook a ele.

**Reasoning**:
Re-initialize the Git repository and attempt to locate the notebook file again.
"""

!git init
!ls

"""**Reasoning**:
The notebook file is not visible in the current directory. I will try to find it using `ls -a` to see if it's a hidden file.


"""

!ls -a

"""## Fazer o commit das alterações

### Subtask:
Make a commit of the changes to save a snapshot of the notebook in Git.

## Criar um repositório no github

### Subtask:
Você precisará criar um novo repositório na sua conta do GitHub. Eu vou te guiar sobre como fazer isso.

## Conectar o repositório local ao github

### Subtask:
Conectar o repositório Git do seu Colab ao novo repositório que você criou no GitHub.

## Enviar o projeto para o github

### Subtask:
Finalmente, enviaremos seu notebook para o GitHub, onde ele estará salvo e acessível.

**Reasoning**:
To push the notebook to the GitHub repository, I need to execute the `git push` command. Since this is a shell command, I will use the `!` prefix.
"""

!git push origin main

"""**Reasoning**:
The error "src refspec main does not match any" indicates that there is no `main` branch in the local repository. This is because no commits have been made yet. Before pushing, I need to add the files and create a commit. Since the notebook file is not directly accessible, I will add all the files in the current directory, which is the best I can do in this environment. Then, I will commit the changes and retry the push.


"""

!git add .
!git commit -m "Initial commit"
!git push origin main